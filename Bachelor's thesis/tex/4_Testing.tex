%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Unit tests %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Unit tests}
Alongside with the development automatic testing was performed using unit tests. Unit tests are designed to verify the
correct functioning of the parts of the application.

Unit testing code means validation or performing the sanity check of code. Sanity check is a basic test to quickly
evaluate whether the result of calculation can possibly be true. It is a simple check to see whether the produced
material is coherent. \cite{unittesting}

\subsection{Django REST tests}
For testing, native tools were used, namely the Django REST framework tests. Similar to java JUnit tests Django tests
are class-based. Every test case is a method of the class, that extends \class{APITestCase} from the module
\module{rest\_framework.test}. Classes can also contain the following methods:

\begin{itemize}
\item{setUp}: Method called to prepare the test fixture.
\item{tearDown}: Method called immediately after the test method has been called and the result recorded.
\end{itemize}

For testing, Django creates a separate empty database independent of the main database. Sqlite DBMS is used for testing
in this project.

\subsection{Auxiliary methods}
For testing of the server API, I wrote a set of auxiliary methods that simulate HTTP requests to the server. This
methods take URL to which the requeste is sent and optionaly information (JSON) which is sent as the body of the
request. Methods use \class{APIRequestFactory} to perform requests to the server.

Methods also use \method{force\_authenticate} function that allows to authenticate user (in this case test user) in the
system without involvement of Facebook. This function is used for testing of requests that require authorization.


\subsection{Test cases}
As an example of a test, I'll take the creation of the wish by the user.

Initially in the method \method{setUp} I create test user, after that I make a POST request to the server with
information about the wish in the body of the request. After the server responded, I check status code of the response,
compare the information between the body of the request and the body of the response (body of the response contains
the newly created wish) and check that wish is added to the database.

\begin{lstlisting}
from django.urls import reverse
from rest_framework.test import APITestCase
from rest_framework import status
from account.models import User, UserManager
from wishes.models import Wish

# auxiliary methods for http requests
from util.test_requests import post, get, put, patch, delete

class WishesTest(APITestCase):

  def setUp(self):
    self.url = reverse('wishes:wishes')
    self.user = UserManager().create_user('test1@test.com', 'test')

  def test_create_wish(self):
    wish_data = {
      'title': "iPhone7",
      'description': "I don't need no jack",
      'amount': 19999
    }
    status_code, response_data = post(url=self.url,
                                      user=self.user,
                                      data=wish_data)

    self.assertEqual(status_code, status.HTTP_201_CREATED)
    self.assertEqual(response_data['title'], wish_data['title'])
    self.assertEqual(response_data['amount'], wish_data['amount'])
    self.assertEqual(Wish.objects.get().title, wish_data['title'])

\end{lstlisting}

This is a positive test, so the status code must be 201 (created), wish should be created and added to the database.

\subsection{Results}



\newcommand{\flag}[1]{
\item[]-\textbf{#1}
}

\newcommand{\bnitem}[1]{
\item\textbf{#1}.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Apachebench %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Apachebench}
Apachebench tool was used to test server performance. Apachebench is a open source, single-threaded command line program
for benchmarking a web server.

Tests were conducted on different \ac{URL}s, with different methods including GET and POST. Example of a testing will be
GET request on "wishes/" \ac{URL}, that returns list of wishes of the current user. It is one of the most popular
requests. During the GET request on this \ac{URL}, the server makes one SELECT-WHERE request to the database.

Testing command looks like this:

\begin{lstlisting}[language=bash]
HEADERS=(
        "Authorization: Token b0edca023c283518f20b36894708" \
        "User-Agent: test-agent"\
        )
URL="https://api.elateme.com/wishes/"

curl -sL "${HEADERS[@]/#/-H}" "$URL"

ab -c 100 -n 5000 "${HEADERS[@]/#/-H}" "$URL"
\end{lstlisting}
Before testing itself, it is checked, with the \bash{curl} utility, if the headers and \ac{URL} are valid and it is
possible to get a successfull responce with them.

In this case, \bash{curl} should print "200", which means a successful request. Further testing with the same headers
and \ac{URL} is conducted. The ab (Apachebench) utility offers two main flags:

\begin{itemize}
\flag{c} Number of multiple requests to perform at a time.
\flag{n} Number of requests to perform for the benchmarking session.
\end{itemize}

This test sends 5000 requests to the server with 100 simultaneous connections.

After testing, ab writes out the statistics, which includes time taken for tests, requests per second, average per
request, etc. The main analyzed indicator was "requests per second".

\subsection{Testing results and optimisation}
After the first test, the request per second rate was about 25, which is a very low rate.

To optimize the performance of the server, it is necessary to find a bottleneck point. There are several possible
problematic places:

\begin{itemize}
\bnitem{Database} Slow connection, long requests processing.
\bnitem{Django} Unsuitable Django configuration.
\bnitem{Gunicorn} Unsuitable configuration of Gunicorn, wrong number of workers, slow logging, etc.
\bnitem{Nginx} Incorrect proxy configuration, wrong number of workers, logging, caching, static files, etc.
\bnitem{Hardware} Low hardware performance.
\end{itemize}

To find a problematic place, it is necessary to test each of the above-mentioned parts separately.

\subsection{Database test}
Database testing is quite simple: sending a large number of requests and timing duration of execution. This was done
directly through Django to test all the parts involved in connecting to the database at once (Django, python,
PostgreSQL).

The test looks like this:

\begin{lstlisting}
def test_db(requests_per_user):
    start = datetime.now()
    users = User.objects.all()
    for i in range(requests_per_user):
        for u in users:
            wishes = u.wishes.all()
    time = (datetime.now() - start).total_seconds()
    total_requests = requests_per_user * users.count()
    print(total_requests, 'requests per', time, 'seconds')
    print(total_requests/time, 'req/sec')

test_db(1000)
\end{lstlisting}

The test checks how long it takes to get each user's wishes separately from the database 1000 times. At the time of
testing, 23 users were stored in the database with 5 to 30 wishes each.

Output of the test:

\begin{lstlisting}[language=]
23000 requests per 7.23 seconds
3178.34 req/sec
\end{lstlisting}

As seen, the database is capable of serving more than three thousand requests per second, so the problem is not in it.


\subsection{Django test}
To test Django separately from nginx (without a proxy), it was enough to run the Apachebench locally on the port on
which Django server is running:

\begin{lstlisting}[language=bash]
URL="127.0.0.1:8888/wishes/"
ab -c 20 -n 1500 "${HEADERS[@]/#/-H}" "$URL"
\end{lstlisting}

This test showed that one instance of the Django server itself serves about 11 requests per second. This indicates that
the problem is in Django and/or hardware performance. Same tests of this Django project on authors local machine showed
much better results, about 350 requests per second.


\subsection{nginx test}
To test nginx separately from Django application, it was enough to make virtualhost that served static page, test.html.
Here is a testing of this page:

\begin{lstlisting}[language=bash]
ab -c 100 -n 5000 "https://api.elateme.com/test.html"
\end{lstlisting}

Results of this test showed similar rate as requests to the \ac{URL}s of server \ac{API}. This indicates that the
problem is in nginx and/or hardware performance.


\subsection{Results}
Taking into consideration everything mentioned above the problem is presumably in server's hardware. Currently, server
is running on the free \ac{VPS}, which is not designed for enterprise projects so testing on current server is not a
true indicator of project performance. Therefore performance tests will be conducted again after backend application is
deployed on full-fledged server.


